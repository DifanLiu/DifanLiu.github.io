<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Difan Liu</title>
  
  <meta name="author" content="Difan Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Difan Liu</name>
              </p>
              <p>I am a research scientist at <a href="https://research.adobe.com/">Adobe Research</a>, where I work on computer graphics, computer vision and machine learning.
              </p>
              <p>
                I received my PhD from <a href="https://www.cics.umass.edu/">UMass Amherst</a> advised by <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a>. Prior to UMass Amherst, I got my bachelor's degree with honors in Electrical Engineering from <a href="http://en.ustc.edu.cn/">University of Science and Technology of China</a>.
              </p>
              <p><strong><span style="font-size: 15px">Internships:</span></strong> I'm always happy to host
                research interns at Adobe Research. If you are interested in working with me, please send me an
                email describing your past experience and current research interests.
              </p>
              <p style="text-align:center">
                <a href="mailto:diliu@adobe.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=FHtM5MUAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href=https://github.com/DifanLiu>Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/difan_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/difan_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests include generative models, vector graphics and video generation. I am
                particularly interested in the synthesis and editing of images, video and vector graphics based on machine learning.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- VecFusion -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/cvpr24vecfusion.png' width="100%" height="55%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>VecFusion: Vector Font Generation with Diffusion</papertitle>
              </a>
              <br>
              <a href="https://vikastmz.github.io/">Vikas Thamizharasan</a>*,
              <strong><span style="font-size: 15px">Difan Liu</span></strong>*,
              Shantanu Agarwal,
              <a href="https://techmatt.github.io/">Matthew Fisher</a>,
              <a href="http://mgharbi.com/">Michaël Gharbi</a>,
              <a href="https://www.oliverwang.info/">Oliver Wang</a>,
              <a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a>,
              <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a>
              <br>
              (*equal contribution) <br>
              <em>CVPR</em>, 2024  &nbsp <font color="red"><strong>(Highlight)</strong></font> <br>
              <a href="https://arxiv.org/abs/2312.10540">PDF</a>
              <p></p>
            </td>
          </tr> 

          <!-- NIVeL -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/cvpr24nivel.png' width="100%" height="55%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>NIVeL: Neural Implicit Vector Layers for Text-to-Vector Generation</papertitle>
              </a>
              <br>
              <a href="https://vikastmz.github.io/">Vikas Thamizharasan</a>,
              <strong><span style="font-size: 15px">Difan Liu</span></strong>,
              <a href="https://techmatt.github.io/">Matthew Fisher</a>,
              <a href="http://nxzhao.com/">Nanxuan Zhao</a>,
              <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a>,
              <a href="https://research.adobe.com/person/michal-lukac/">Michal Lukáč</a>
              <br>
              <em>CVPR</em>, 2024 <br>
              Paper to appear soon
              <p></p>
            </td>
          </tr> 

          <!-- Visual Layout Composer -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/cvpr24layout.png' width="110%" height="55%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Visual Layout Composer: Image-Vector Dual Diffusion Model for Design Layout Generation</papertitle>
              </a>
              <br>
              <a href="https://aminshabani.github.io/">Mohammad Amin Shabani</a>,
              <a href="https://research.adobe.com/person/zhaowen-wang/">Zhaowen Wang</a>,
              <strong><span style="font-size: 15px">Difan Liu</span></strong>,
              <a href="http://nxzhao.com/">Nanxuan Zhao</a>,
              <a href="https://jimeiyang.github.io/">Jimei Yang</a>,
              <a href="https://yasu-furukawa.github.io/">Yasutaka Furukawa</a>
              <br>
              <em>CVPR</em>, 2024 <br>
              Paper to appear soon
              <p></p>
            </td>
          </tr> 


          <!-- AT-EDM -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/cvpr24atedm.png' width="160" height="85.74">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models</papertitle>
              </a>
              <br>
              <a href="https://hongjiew.github.io/">Hongjie Wang</a>,
              <strong><span style="font-size: 15px">Difan Liu</span></strong>,
              <a href="https://research.adobe.com/person/yan-kang/">Yan Kang</a>,
              <a href="https://yijunmaverick.github.io/">Yijun Li</a>,
              <a href="https://sites.google.com/site/zhelin625/">Zhe Lin</a>,
              <a href="https://www.princeton.edu/~jha/">Niraj Jha</a>,
              <a href="https://lychenyoko.github.io/">Yuchen Liu</a>
              <br>
              <em>CVPR</em>, 2024 <br>
              Paper to appear soon
              <p></p>
            </td>
          </tr> 

          <!-- SNED -->
              <tr>
                <td>
                  <video autoplay muted loop playsinline width="190" height="106.81">
                    <source src="images/SNED_example.mp4"
                            type="video/mp4">
                  </video>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="">
                    <papertitle>SNED: Superposition Network Architecture Search for Efficient Video Diffusion Model</papertitle>
                  </a>
                  <br>
                  Zhengang Li,
                  <a href="https://research.adobe.com/person/yan-kang/">Yan Kang</a>,
                  <a href="https://lychenyoko.github.io/">Yuchen Liu</a>,
                  <strong><span style="font-size: 15px">Difan Liu</span></strong>,
                  <a href="https://www.tobiashinz.com/">Tobias Hinz</a>,
                  <a href="https://research.adobe.com/person/feng-liu/">Feng Liu</a>,
                  <a href="https://web.northeastern.edu/yanzhiwang/">Yanzhi Wang</a>
                  <br>
                  <em>CVPR</em>, 2024 <br>
                  Paper to appear soon
                  <p></p>
                </td>
              </tr> 

          <!-- LRM -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <video autoplay muted loop playsinline width="152.75" height="96">
                    <source src="images/LRM_example.mp4"
                            type="video/mp4">
                  </video>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://yiconghong.me/LRM/">
                    <papertitle>LRM: Large Reconstruction Model for Single Image to 3D</papertitle>
                  </a>
                  <br>
                  <a href="https://yiconghong.me/">Yicong Hong</a>,
                  <a href="https://kai-46.github.io/website/">Kai Zhang</a>,
                  <a href="https://gujiuxiang.com/">Jiuxiang Gu</a>,
                  <a href="https://sai-bi.github.io/">Sai Bi</a>,
                  <a href="https://yzhou359.github.io/">Yang Zhou</a>,
                  <strong><span style="font-size: 15px">Difan Liu</span></strong>,
                  <a href="https://research.adobe.com/person/feng-liu/">Feng Liu</a>,
                  <a href="https://research.adobe.com/person/kalyan-sunkavalli/">Kalyan Sunkavalli</a>,
                  <a href="https://sites.google.com/site/trungbuistanford/">Trung Bui</a>,
                  <a href="https://research.adobe.com/person/hao-tan/">Hao Tan</a>
                  <br>
                  <em>ICLR</em>, 2024  &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br> 
                  <a href="https://arxiv.org/abs/2311.04400">PDF</a>
                  /
                  <a href="https://yiconghong.me/LRM/">Project</a>
                  <p></p>
                </td>
              </tr> 

          <!-- ASSET -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/sig22.jpg' width="100%" height="55%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://people.cs.umass.edu/~dliu/projects/ASSET/">
                    <papertitle>ASSET: Autoregressive Semantic Scene Editing with Transformers at High Resolutions</papertitle>
                  </a>
                  <br>
                  <strong><span style="font-size: 15px">Difan Liu</span></strong>,
                  Sandesh Shetty,
                  <a href="http://www.tobiashinz.com/">Tobias Hinz</a>,
                  <a href="https://techmatt.github.io/">Matthew Fisher</a>,
                  <a href="https://richzhang.github.io/">Richard Zhang</a>,
                  <a href="https://taesung.me/">Taesung Park</a>,
                  <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a>
                  <br>
                  <em>SIGGRAPH - Journal Track</em>, 2022 <br>
                  <a href="http://people.cs.umass.edu/~dliu/papers/ASSET_low_res.pdf">PDF(low-res)</a>
                  /
                  <a href="https://www.dropbox.com/s/he46f2ljsd61tdz/ASSET.pdf?dl=0">PDF(high-res)</a>
                  /
                  <a href="https://people.cs.umass.edu/~dliu/projects/ASSET/">Project</a>
                  <p></p>
                </td>
              </tr> 

              <!-- NS -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/iccv21ns.png' width="80%" height="55%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://people.cs.umass.edu/~dliu/projects/NeuralStrokes/">
                    <papertitle>Neural Strokes: Stylized Line Drawing of 3D Shapes</papertitle>
                  </a>
                  <br>
                  <strong><span style="font-size: 15px">Difan Liu</span></strong>,
                  <a href="https://techmatt.github.io/">Matthew Fisher</a>,
                  <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a>,
                  <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a>
                  <br>
                  <em>ICCV</em>, 2021 <br>
                  <a href="http://people.cs.umass.edu/~dliu/papers/NeuralStrokes.pdf">PDF</a>
                  /
                  <a href="https://people.cs.umass.edu/~dliu/projects/NeuralStrokes/">Project</a>
                  <p></p>
                </td>
              </tr> 

              <!-- NC -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/cvpr20.jpeg' width="100%" height="55%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://people.cs.umass.edu/~dliu/projects/NeuralContours/">
                    <papertitle>Neural Contours: Learning to Draw Lines from 3D Shapes</papertitle>
                  </a>
                  <br>
                  <strong><span style="font-size: 15px">Difan Liu</span></strong>,
                  Mohamed Nabail,
                  <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a>,
                  <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a>
                  <br>
                  <em>CVPR</em>, 2020 <br>
                  <a href="http://people.cs.umass.edu/~dliu/papers/NeuralContours.pdf">PDF</a>
                  /
                  <a href="https://people.cs.umass.edu/~dliu/projects/NeuralContours/">Project</a>
                  <p></p>
                </td>
              </tr> 

              <!-- ParSeNet -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/eccv2020.jpeg' width="100%" height="55%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://hippogriff.github.io/parsenet/">
                    <papertitle>ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds</papertitle>
                  </a>
                  <br>
                  <a href="https://hippogriff.github.io/">Gopal Sharma</a>,
                  <strong><span style="font-size: 15px">Difan Liu</span></strong>,
                  <a href="https://people.cs.umass.edu/~smaji/">Subhransu Maji</a>,
                  <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a>,
                  <a href="https://www.cse.iitb.ac.in/~sidch/">Siddhartha Chaudhuri</a>,
                  <a href="https://research.adobe.com/person/radomir-mech/">Radomír Měch</a>
                  <br>
                  <em>ECCV</em>, 2020 <br>
                  <a href="https://arxiv.org/pdf/2003.12181.pdf">PDF</a>
                  /
                  <a href="https://hippogriff.github.io/parsenet/">Project</a>
                  <p></p>
                </td>
              </tr>

              <!-- CSGNet-2 -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/stackcsgnet.png' width="100%" height="55%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="">
                    <papertitle>Neural Shape Parsers for Constructive Solid Geometry</papertitle>
                  </a>
                  <br>
                  <a href="https://hippogriff.github.io/">Gopal Sharma</a>,
                  Rishabh Goyal,
                  <strong><span style="font-size: 15px">Difan Liu</span></strong>,
                  <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a>,
                  <a href="https://people.cs.umass.edu/~smaji/">Subhransu Maji</a>
                  <br>
                  <em>TPAMI</em>, 2020 <br>
                  <a href="https://ieeexplore.ieee.org/document/9293398">PDF</a>
                  /
                  <a href="https://github.com/Hippogriff/CSGNet">Code</a>
                  <p></p>
                </td>
              </tr>

              <!-- Deep Part Induction -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/sigasia18.png' width="100%" height="55%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="">
                    <papertitle>Deep Part Induction from Articulated Object Pairs</papertitle>
                  </a>
                  <br>
                  <a href="https://ericyi.github.io/">Li Yi</a>,
                  <a href="https://brotherhuang.github.io/">Haibin Huang</a>,
                  <strong><span style="font-size: 15px">Difan Liu</span></strong>,
                  <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a>,
                  <a href="https://cseweb.ucsd.edu/~haosu/">Hao Su</a>,
                  <a href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>
                  <br>
                  <em>SIGGRAPH Asia</em>, 2018 <br>
                  <a href="https://arxiv.org/pdf/1809.07417.pdf">PDF</a>
                  /
                  <a href="https://github.com/ericyi/articulated-part-induction">Code</a>
                  <p></p>
                </td>
              </tr>

              <!-- CSGNet -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/cvpr18b.jpeg' width="100%" height="55%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="">
                    <papertitle>CSGNet: Neural Shape Parser for Constructive Solid Geometry</papertitle>
                  </a>
                  <br>
                  <a href="https://hippogriff.github.io/">Gopal Sharma</a>,
                  Rishabh Goyal,
                  <strong><span style="font-size: 15px">Difan Liu</span></strong>,
                  <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a>,
                  <a href="https://people.cs.umass.edu/~smaji/">Subhransu Maji</a>
                  <br>
                  <em>CVPR</em>, 2018 <br>
                  <a href="https://people.cs.umass.edu/~kalo/papers/CSGNet/CSGNet.pdf">PDF</a>
                  /
                  <a href="https://github.com/Hippogriff/CSGNet">Code</a>
                  <p></p>
                </td>
              </tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Product Impacts, Tech Transfers, and Demos</heading>
            <p>
              <li><a href="https://www.adobe.com/products/firefly/features/text-to-image.html">Firefly Text to Image</a> in <a href="https://www.adobe.com/express/">Express</a> and <a href="https://www.adobe.com/sensei/generative-ai/firefly.html">Firefly</a>, 2023</li>
              <li><a href="https://www.youtube.com/watch?v=ps_MpkKrqoA">Project Glyph Ease</a> at Adobe MAX Sneaks, 2023</li>
              <li><a href="https://www.youtube.com/watch?v=MnOVEcst_U4">Project Res Up</a> at Adobe MAX Sneaks, 2023</li>
            </p>
          </td>
        </tr>
      </tbody></table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right">
                  <font size="2">
                    <a href="https://jonbarron.info/">This webpage is cool</a>
                  </font>
                </p>
              </td>
            </tr>
    </tbody>
  </table>
				

      </td>
    </tr>
  </table>
</body>

</html>
